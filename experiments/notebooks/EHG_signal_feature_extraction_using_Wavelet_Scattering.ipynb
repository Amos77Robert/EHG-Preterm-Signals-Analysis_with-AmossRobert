{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Install required Libraries"
      ],
      "metadata": {
        "id": "fZlVZbNi65fi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wfdb\n",
        "!pip install kymatio\n",
        "!pip install torch"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "qwlFvvuw7Ari",
        "outputId": "fc9d3086-3118-41fd-ddea-aaa4368745b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting wfdb\n",
            "  Downloading wfdb-4.1.2-py3-none-any.whl.metadata (4.3 kB)\n",
            "Requirement already satisfied: SoundFile>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from wfdb) (0.12.1)\n",
            "Requirement already satisfied: matplotlib>=3.2.2 in /usr/local/lib/python3.10/dist-packages (from wfdb) (3.8.0)\n",
            "Requirement already satisfied: numpy>=1.10.1 in /usr/local/lib/python3.10/dist-packages (from wfdb) (1.26.4)\n",
            "Requirement already satisfied: pandas>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from wfdb) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from wfdb) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wfdb) (1.13.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->wfdb) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->wfdb) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->wfdb) (4.55.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->wfdb) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->wfdb) (24.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->wfdb) (11.0.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->wfdb) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->wfdb) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.3.0->wfdb) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.3.0->wfdb) (2024.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.8.1->wfdb) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.8.1->wfdb) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.8.1->wfdb) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.8.1->wfdb) (2024.8.30)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from SoundFile>=0.10.0->wfdb) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->SoundFile>=0.10.0->wfdb) (2.22)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.2.2->wfdb) (1.16.0)\n",
            "Downloading wfdb-4.1.2-py3-none-any.whl (159 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m160.0/160.0 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: wfdb\n",
            "Successfully installed wfdb-4.1.2\n",
            "Collecting kymatio\n",
            "  Downloading kymatio-0.3.0-py3-none-any.whl.metadata (9.6 kB)\n",
            "Collecting appdirs (from kymatio)\n",
            "  Downloading appdirs-1.4.4-py2.py3-none-any.whl.metadata (9.0 kB)\n",
            "Collecting configparser (from kymatio)\n",
            "  Downloading configparser-7.1.0-py3-none-any.whl.metadata (5.4 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from kymatio) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from kymatio) (24.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from kymatio) (1.13.1)\n",
            "Downloading kymatio-0.3.0-py3-none-any.whl (87 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.6/87.6 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
            "Downloading configparser-7.1.0-py3-none-any.whl (17 kB)\n",
            "Installing collected packages: appdirs, configparser, kymatio\n",
            "Successfully installed appdirs-1.4.4 configparser-7.1.0 kymatio-0.3.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "backports"
                ]
              },
              "id": "c9993b53ceb54fd2b1252d332b01f6a8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import libraries"
      ],
      "metadata": {
        "id": "K-YhkLqvb_Db"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yOTIvEMDyJgu"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import wfdb\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "from kymatio.torch import Scattering1D\n",
        "import torch"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Load data\n",
        "\n",
        "> Add blockquote\n",
        "\n"
      ],
      "metadata": {
        "id": "19obLmqF7cJh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9bIg0ly77i1d",
        "outputId": "3998f6c7-d6f4-40de-b8ac-00b762fc9fac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A function to load the Electrohysterograph(EHG) signals"
      ],
      "metadata": {
        "id": "3g3MD07wmuoz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_signals(base_folder):\n",
        "    \"\"\"\n",
        "    Loads EHG signals from the specified folder structure.\n",
        "    Args:\n",
        "        base_folder: The root folder containing class subfolders.\n",
        "    Returns:\n",
        "        signals: List of loaded signals (numpy arrays).\n",
        "        labels: Corresponding labels of each signal.\n",
        "    \"\"\"\n",
        "    signals = []\n",
        "    labels = []\n",
        "    classes = os.listdir(base_folder)  # Class folders\n",
        "\n",
        "    for label in classes:\n",
        "        folder_path = os.path.join(base_folder, label)\n",
        "        if not os.path.isdir(folder_path):\n",
        "            continue\n",
        "\n",
        "        for file in os.listdir(folder_path):\n",
        "            if file.endswith('.dat'):\n",
        "                file_base = file.split('.')[0]\n",
        "                dat_path = os.path.join(folder_path, file_base)\n",
        "\n",
        "                # Load signal using WFDB\n",
        "                record = wfdb.rdrecord(dat_path)\n",
        "                signal = record.p_signal  # Extract signals as numpy array\n",
        "\n",
        "                # Filter only DOCFILT signals\n",
        "                filtered_indices = [\n",
        "                    idx for idx, sig in enumerate(record.sig_name) if \"DOCFILT\" in sig\n",
        "                ]\n",
        "                filtered_signal = signal[:, filtered_indices]  # Select filtered signals\n",
        "\n",
        "                signals.append(filtered_signal)\n",
        "                labels.append(label)  # Label is the folder name\n",
        "\n",
        "    return signals, labels\n"
      ],
      "metadata": {
        "id": "s1tcW0XNmzud"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A function to adjust the signal length to match the target length by padding or truncating."
      ],
      "metadata": {
        "id": "8vy-CoYUpYCh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def adjust_signal_length(signal, target_length):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "        signal: The input signal (1D numpy array).\n",
        "        target_length: The desired length (int).\n",
        "\n",
        "    Returns:\n",
        "        Adjusted signal of the target length.\n",
        "    \"\"\"\n",
        "    current_length = signal.shape[0]  # The number of samples in the signal\n",
        "    if current_length > target_length:\n",
        "        return signal[:target_length]     # Truncate\n",
        "    elif current_length < target_length:\n",
        "        padding = target_length - current_length   # Pad with zeros\n",
        "        return np.pad(signal, (0, padding), mode='constant')\n",
        "    return signal\n"
      ],
      "metadata": {
        "id": "DxaYJUWinkay"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's now extract features and save to excel file"
      ],
      "metadata": {
        "id": "V5pbxNwhpfA6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We are applying a wevelet scattering algorithm"
      ],
      "metadata": {
        "id": "6YUCzkw0dXBk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_features_and_save(signals, labels, output_file, scattering):\n",
        "    \"\"\"\n",
        "    Extract features using Wavelet Scattering and save them to an Excel file.\n",
        "\n",
        "    Args:\n",
        "        signals: List of signals.\n",
        "        labels: List of corresponding labels.\n",
        "        output_file: Path to save the Excel file.\n",
        "        scattering: Scattering1D object for feature extraction.\n",
        "    \"\"\"\n",
        "    features_list = []\n",
        "    target_length = scattering.shape  # Get required length for Scattering1D\n",
        "    target_length = target_length[0]  # Extract as an integer\n",
        "\n",
        "    for i, (signal, label) in enumerate(zip(signals, labels)):\n",
        "        print(f\"Processing signal {i+1}/{len(signals)}\")\n",
        "\n",
        "        # Adjust signal length for each channel\n",
        "        signal_tensor = torch.tensor([\n",
        "            adjust_signal_length(signal[:, ch], target_length) for ch in range(signal.shape[1])\n",
        "        ], dtype=torch.float32)  # Shape: (channels, target_length)\n",
        "\n",
        "        # Extract features for each channel\n",
        "        for ch in range(signal_tensor.shape[0]):\n",
        "            scattering_features = scattering(signal_tensor[ch, :])\n",
        "            features_flattened = scattering_features.numpy().flatten()  # Flatten features into a single row\n",
        "\n",
        "            # Add features and metadata to the list\n",
        "            features_list.append({\n",
        "                **{f\"feature_{i}\": val for i, val in enumerate(features_flattened)},\n",
        "                \"label\": label,\n",
        "                \"channel\": f\"channel_{ch+1}\"  # Channel identifier\n",
        "            })\n",
        "\n",
        "    df = pd.DataFrame(features_list)\n",
        "    df.to_excel(output_file, index=False)\n",
        "    print(f\"Features saved to {output_file}\")\n"
      ],
      "metadata": {
        "id": "5__UYtiXpmLw"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Main Script"
      ],
      "metadata": {
        "id": "WMRIHkiMp5O7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "base_folder = '/content/drive/My Drive/EHG'  # Adjust to your folder path\n",
        "output_excel_file = '/content/drive/My Drive/EHG_Preterm_Birth_Signals_Data_Features.xlsx'\n",
        "\n",
        "#Load signals and labels\n",
        "signals, labels = load_signals(base_folder)\n",
        "\n",
        "#Scattering Network\n",
        "scattering = Scattering1D(J=5, shape=(2**13,))  # Example: 8192 target length\n",
        "\n",
        "extract_features_and_save(signals, labels, output_excel_file, scattering)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Bv5Loisip6UD",
        "outputId": "3f85c9ad-cfe8-40e2-9b17-e8800c477bd0"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing signal 1/126\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-6-da19f83925aa>:19: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
            "  signal_tensor = torch.tensor([\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing signal 2/126\n",
            "Processing signal 3/126\n",
            "Processing signal 4/126\n",
            "Processing signal 5/126\n",
            "Processing signal 6/126\n",
            "Processing signal 7/126\n",
            "Processing signal 8/126\n",
            "Processing signal 9/126\n",
            "Processing signal 10/126\n",
            "Processing signal 11/126\n",
            "Processing signal 12/126\n",
            "Processing signal 13/126\n",
            "Processing signal 14/126\n",
            "Processing signal 15/126\n",
            "Processing signal 16/126\n",
            "Processing signal 17/126\n",
            "Processing signal 18/126\n",
            "Processing signal 19/126\n",
            "Processing signal 20/126\n",
            "Processing signal 21/126\n",
            "Processing signal 22/126\n",
            "Processing signal 23/126\n",
            "Processing signal 24/126\n",
            "Processing signal 25/126\n",
            "Processing signal 26/126\n",
            "Processing signal 27/126\n",
            "Processing signal 28/126\n",
            "Processing signal 29/126\n",
            "Processing signal 30/126\n",
            "Processing signal 31/126\n",
            "Processing signal 32/126\n",
            "Processing signal 33/126\n",
            "Processing signal 34/126\n",
            "Processing signal 35/126\n",
            "Processing signal 36/126\n",
            "Processing signal 37/126\n",
            "Processing signal 38/126\n",
            "Processing signal 39/126\n",
            "Processing signal 40/126\n",
            "Processing signal 41/126\n",
            "Processing signal 42/126\n",
            "Processing signal 43/126\n",
            "Processing signal 44/126\n",
            "Processing signal 45/126\n",
            "Processing signal 46/126\n",
            "Processing signal 47/126\n",
            "Processing signal 48/126\n",
            "Processing signal 49/126\n",
            "Processing signal 50/126\n",
            "Processing signal 51/126\n",
            "Processing signal 52/126\n",
            "Processing signal 53/126\n",
            "Processing signal 54/126\n",
            "Processing signal 55/126\n",
            "Processing signal 56/126\n",
            "Processing signal 57/126\n",
            "Processing signal 58/126\n",
            "Processing signal 59/126\n",
            "Processing signal 60/126\n",
            "Processing signal 61/126\n",
            "Processing signal 62/126\n",
            "Processing signal 63/126\n",
            "Processing signal 64/126\n",
            "Processing signal 65/126\n",
            "Processing signal 66/126\n",
            "Processing signal 67/126\n",
            "Processing signal 68/126\n",
            "Processing signal 69/126\n",
            "Processing signal 70/126\n",
            "Processing signal 71/126\n",
            "Processing signal 72/126\n",
            "Processing signal 73/126\n",
            "Processing signal 74/126\n",
            "Processing signal 75/126\n",
            "Processing signal 76/126\n",
            "Processing signal 77/126\n",
            "Processing signal 78/126\n",
            "Processing signal 79/126\n",
            "Processing signal 80/126\n",
            "Processing signal 81/126\n",
            "Processing signal 82/126\n",
            "Processing signal 83/126\n",
            "Processing signal 84/126\n",
            "Processing signal 85/126\n",
            "Processing signal 86/126\n",
            "Processing signal 87/126\n",
            "Processing signal 88/126\n",
            "Processing signal 89/126\n",
            "Processing signal 90/126\n",
            "Processing signal 91/126\n",
            "Processing signal 92/126\n",
            "Processing signal 93/126\n",
            "Processing signal 94/126\n",
            "Processing signal 95/126\n",
            "Processing signal 96/126\n",
            "Processing signal 97/126\n",
            "Processing signal 98/126\n",
            "Processing signal 99/126\n",
            "Processing signal 100/126\n",
            "Processing signal 101/126\n",
            "Processing signal 102/126\n",
            "Processing signal 103/126\n",
            "Processing signal 104/126\n",
            "Processing signal 105/126\n",
            "Processing signal 106/126\n",
            "Processing signal 107/126\n",
            "Processing signal 108/126\n",
            "Processing signal 109/126\n",
            "Processing signal 110/126\n",
            "Processing signal 111/126\n",
            "Processing signal 112/126\n",
            "Processing signal 113/126\n",
            "Processing signal 114/126\n",
            "Processing signal 115/126\n",
            "Processing signal 116/126\n",
            "Processing signal 117/126\n",
            "Processing signal 118/126\n",
            "Processing signal 119/126\n",
            "Processing signal 120/126\n",
            "Processing signal 121/126\n",
            "Processing signal 122/126\n",
            "Processing signal 123/126\n",
            "Processing signal 124/126\n",
            "Processing signal 125/126\n",
            "Processing signal 126/126\n",
            "Features saved to /content/drive/My Drive/EHG_Preterm_Birth_Signals_Data_Features.xlsx\n"
          ]
        }
      ]
    }
  ]
}